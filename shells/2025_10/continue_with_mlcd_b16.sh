torchrun \
--nproc_per_node 8 \
--nnodes 8 \
--node_rank $1 \
--rdzv_backend=c10d \
--rdzv_endpoint=${INTERNAL_IP:-127.0.0.1}:22347 \
--rdzv_id=llava-vit-20251011 \
-m training.train_univit \
  --model_name pretrain_encoder_base_patch16_224_v10_12_rms_unmask_with_head \
  --embedding_size 768 \
  --list_batch_sizes 32 32 \
  --num_sampled_data 150000000 \
  --list_datasets k710_ssv2_univit_pfs mlcd_coyo_laion \
  --list_init_partial_fc_paths NULL /vlm/VideoMLCD/checkpoints/llava_vit_b_16.py/00390626/MLCD_in_pfs/MLCD_in_pfs_%03d.pt \
  --init_backbone ${INIT_BACKBONE} \
  --output ${OUTPUT_DIR:-./output} $0 .sh`
